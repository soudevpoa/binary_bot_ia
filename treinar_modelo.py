import asyncio
import json
import numpy as np
import os
from core.modelo_neural import ModeloNeural
# Deixamos os imports abaixo caso voc√™ decida usar indicadores no futuro, mas n√£o s√£o usados agora.
from indicadores.indicadores import calcular_rsi, calcular_mm, calcular_volatilidade 
from core.mercado import Mercado
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# Define o n√∫mero de ticks que voc√™ quer usar para o treinamento.
NUMERO_TICKS_TREINO = 50000 

async def coletar_dados(token, ativo, num_ticks):
    """Fun√ß√£o para coletar ticks do mercado."""
    mercado = Mercado("wss://ws.derivws.com/websockets/v3?app_id=1089", token, ativo)
    await mercado.conectar()
    await mercado.autenticar(token)
    await mercado.subscrever_ticks(ativo)

    prices = []
    print(f"üì¶ Coletando {num_ticks} ticks do {ativo}...")
    for _ in range(num_ticks):
        try:
            msg = await mercado.ws.recv()
            data = mercado.processar_tick(msg)
            if data and data.get('msg_type') == 'tick':
                prices.append(data["price"])
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao coletar ticks: {e}")
            break
    
    await mercado.desconectar()
    print("üîå Conex√£o com o Mercado Deriv fechada.")
    return prices

def preparar_dataset(prices, config):
    """
    ‚úÖ AJUSTE: Prepara o dataset para o treinamento da IA, usando os √∫ltimos N pre√ßos brutos.
    """
    features, labels = [], []
    # Usa o tamanho da janela definido no config.json (200)
    window_size = config.get("tamanho_janela_ia", 200) 

    # O loop precisa de pelo menos o tamanho da janela + 1 para o label
    for i in range(len(prices) - window_size - 1):
        # X: O conjunto de 200 pre√ßos anteriores (features)
        X_subset = prices[i:i + window_size] 
        
        # y: O pr√≥ximo pre√ßo (para definir o label)
        next_price = prices[i + window_size] 

        # A feature √© a lista dos 200 pre√ßos.
        features.append(X_subset) 
        
        # O Label √© 1 para CALL (subida) e 0 para PUT (descida/lateraliza√ß√£o)
        labels.append(1 if next_price > X_subset[-1] else 0)

    return np.array(features), np.array(labels)

async def main():
    """Fun√ß√£o principal para o treinamento do modelo."""
    try:
        if not os.path.exists("configs/config_megalodon.json"):
            raise FileNotFoundError("config_megalodon.json n√£o encontrado. Verifique o caminho.")
        with open("configs/config_megalodon.json", "r") as f:
            config = json.load(f)
    except FileNotFoundError as e:
        print(f"‚ùå Erro: {e}")
        return

    token = config.get("token")
    ativo = config.get("volatility_index")
    window_size = config.get("tamanho_janela_ia", 200)
    
    if not token or not ativo:
        print("‚ùå Erro: Token ou Volatility Index ausentes no config_megalodon.json.")
        return

    prices = await coletar_dados(token, ativo, num_ticks=NUMERO_TICKS_TREINO)

    if not prices:
        print("‚ùå N√£o foi poss√≠vel coletar dados de pre√ßo. Verifique sua conex√£o ou token.")
        return

    print("üß™ Preparando dataset...")
    X, y = preparar_dataset(prices, config)

    if len(X) == 0:
        print("‚ùå Dados insuficientes para treino. Tente aumentar o n√∫mero de ticks ou a janela IA.")
        return
    
    print(f"üß† Treinando modelo com {len(X)} amostras e {window_size} features...")
    # ‚úÖ AJUSTE: Inicializa o modelo com o input_shape correto (200)
    modelo = ModeloNeural(input_shape=window_size) 
    
    # ----------------------------------------------------
    # ‚úÖ AJUSTE CR√çTICO: Normalizar os dados e fitar o Scaler
    # ----------------------------------------------------
    print("‚öñÔ∏è Normalizando e preparando dados...")
    scaler = MinMaxScaler()
    # O scaler √© treinado (fitado) com o conjunto COMPLETO de features X (N, 200)
    X_normalizado = scaler.fit_transform(X) 
    
    # Associa o scaler ao modelo para que ele possa ser salvo e usado na opera√ß√£o
    modelo.scaler = scaler
    
    # Divide os dados normalizados
    X_treino, X_teste, y_treino, y_teste = train_test_split(
        X_normalizado, y, test_size=0.2, random_state=42
    )
    
    print(f"üß† Treinando modelo com {len(X_treino)} amostras de treino...")
    # ----------------------------------------------------
    # ‚úÖ FIM DO AJUSTE
    # ----------------------------------------------------
    
    modelo.treinar(X_treino, y_treino, X_teste, y_teste)

    # Usamos os m√©todos da classe para salvar os arquivos
    print("üíæ Salvando modelo e scaler...")
    modelo.salvar("modelo_megalodon.h5")
    modelo.salvar_scaler("scaler_megalodon.pkl")

    # A acur√°cia deve ser acessada via atributo do modelo ap√≥s o treino (se implementado)
    print(f"‚úÖ Treinamento conclu√≠do e arquivos salvos.") 

if __name__ == "__main__":
    asyncio.run(main())